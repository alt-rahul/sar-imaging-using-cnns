{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import ToTensor, Compose\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_dir, image_dir_2, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.image_dir_2 = image_dir_2\n",
    "        self.image_files = [i for i in os.listdir(image_dir) if i.endswith(('.png', '.jpg', '.jpeg', '.bmp'))]\n",
    "        self.images_files_2 = [i for i in os.listdir(image_dir_2) if i.endswith(('.png', '.jpg', '.jpeg', '.bmp'))]\n",
    "        self.transform = transform\n",
    " \n",
    "    def len(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def getItem(self, dirc, files, idx):\n",
    "        img_path = os.path.join(dirc, files[idx])\n",
    "        image = Image.open(img_path).convert(\"RGB\").to(device)\n",
    "        if self.transform:\n",
    "            image = self.transform(image).to(device)\n",
    "        return image  \n",
    "    \n",
    "    def getDataset(self):\n",
    "        total_dataset = []\n",
    "        for i in range(len(self.image_files)):\n",
    "            if i % 1000 == 0:\n",
    "                print(f\"Have reached {i}/{len(self.image_files)}\")\n",
    "            total_dataset.append([self.getItem(dirc =self.image_dir, files=self.image_files, idx=i), self.getItem(dirc =self.image_dir_2, files=self.images_files_2, idx=i)])\n",
    "        return total_dataset\n",
    "    \n",
    "DATA_DIR = r\"C:\\Users\\rahul\\Documents\\PyFiles\\datasets\\virtual_sar_training_set\\clean_1c\"\n",
    "DATA_DIR_2 = r\"C:\\Users\\rahul\\Documents\\PyFiles\\datasets\\virtual_sar_training_set\\noisy_1c\"\n",
    "\n",
    "transformations = Compose([\n",
    "    ToTensor(), \n",
    "])\n",
    "\n",
    "clean_dataset = ImageDataset(image_dir=DATA_DIR, image_dir_2=DATA_DIR_2, transform=transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have reached 0/31500\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m final_list \u001b[38;5;241m=\u001b[39m clean_dataset\u001b[38;5;241m.\u001b[39mgetDataset()\n",
      "Cell \u001b[1;32mIn[18], line 29\u001b[0m, in \u001b[0;36mImageDataset.getDataset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     28\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHave reached \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_files)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 29\u001b[0m     total_dataset\u001b[38;5;241m.\u001b[39mappend([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetItem(dirc \u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_dir, files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_files, idx\u001b[38;5;241m=\u001b[39mi), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetItem(dirc \u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_dir_2, files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimages_files_2, idx\u001b[38;5;241m=\u001b[39mi)])\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_dataset\n",
      "Cell \u001b[1;32mIn[18], line 21\u001b[0m, in \u001b[0;36mImageDataset.getItem\u001b[1;34m(self, dirc, files, idx)\u001b[0m\n\u001b[0;32m     19\u001b[0m image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(img_path)\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[1;32m---> 21\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(image)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m image\n",
      "File \u001b[1;32me:\\anaconda\\Lib\\site-packages\\torch\\cuda\\__init__.py:310\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m     )\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    313\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    314\u001b[0m     )\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "final_list = clean_dataset.getDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOISE_DATA_DIR = r\"C:\\Users\\rahul\\Documents\\PyFiles\\Notebooks\\papers\\sar_imaging\\virtual_sar_training_set\\noisy_1c\"\n",
    "\n",
    "noise_dataset = ImageDataset(NOISE_DATA_DIR, transform=transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3686, 0.3961, 0.3922,  ..., 0.3059, 0.3412, 0.3020],\n",
       "         [0.4039, 0.4078, 0.3922,  ..., 0.3529, 0.3529, 0.4431],\n",
       "         [0.3961, 0.3804, 0.3686,  ..., 0.3529, 0.3412, 0.2980],\n",
       "         ...,\n",
       "         [0.4039, 0.3882, 0.3098,  ..., 0.2627, 0.2863, 0.2431],\n",
       "         [0.3686, 0.4353, 0.3804,  ..., 0.3137, 0.3451, 0.2902],\n",
       "         [0.4980, 0.3725, 0.4588,  ..., 0.2510, 0.2863, 0.2784]],\n",
       "\n",
       "        [[0.3686, 0.3961, 0.3922,  ..., 0.3059, 0.3412, 0.3020],\n",
       "         [0.4039, 0.4078, 0.3922,  ..., 0.3529, 0.3529, 0.4431],\n",
       "         [0.3961, 0.3804, 0.3686,  ..., 0.3529, 0.3412, 0.2980],\n",
       "         ...,\n",
       "         [0.4039, 0.3882, 0.3098,  ..., 0.2627, 0.2863, 0.2431],\n",
       "         [0.3686, 0.4353, 0.3804,  ..., 0.3137, 0.3451, 0.2902],\n",
       "         [0.4980, 0.3725, 0.4588,  ..., 0.2510, 0.2863, 0.2784]],\n",
       "\n",
       "        [[0.3686, 0.3961, 0.3922,  ..., 0.3059, 0.3412, 0.3020],\n",
       "         [0.4039, 0.4078, 0.3922,  ..., 0.3529, 0.3529, 0.4431],\n",
       "         [0.3961, 0.3804, 0.3686,  ..., 0.3529, 0.3412, 0.2980],\n",
       "         ...,\n",
       "         [0.4039, 0.3882, 0.3098,  ..., 0.2627, 0.2863, 0.2431],\n",
       "         [0.3686, 0.4353, 0.3804,  ..., 0.3137, 0.3451, 0.2902],\n",
       "         [0.4980, 0.3725, 0.4588,  ..., 0.2510, 0.2863, 0.2784]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_clean_data = [i for i in clean_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SARDespeckleModel(nn.Module):\n",
    "    def __init__(self, input_shape:int, hidden_units:int, output_shape:int):\n",
    "        super().__init__()\n",
    "        self.layer_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape, out_channels=hidden_units, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        for i in range(5):\n",
    "            \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
